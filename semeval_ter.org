#+TITLE:Appariement de questions/réponses
#+AUTHOR:Félix Jamet
# -*- org-export-babel-evaluate: t -*-
#+PROPERTY: header-args:ipython :session semexec :eval no-export :results output silent
#+OPTIONS: toc:nil title:nil

\newpage
* Structures de données et algorithmes (=semeval_struct.py=)
:PROPERTIES:
:header-args: :tangle semeval_struct.py
:END:
** Imports
#+BEGIN_SRC ipython
  import re
  import operator
#+END_SRC

** Arbres
*** Transformation en profondeur
Il s'agit ici d'appliquer récursivement une fonction à chacune des feuilles d'un arbre.

#+BEGIN_SRC ipython
  def transformtree_deep(func, tree):
      """Transform a tree by applying a function to its leaves.

      Parameters
      ----------
      func : function
          The function that will transform each leaf.

      tree : recursive dict
          The tree to transform.

      Returns
      -------
      out : recursive dict
          The transformed tree.
      """
      return {
          key: transformtree_deep(func, value)
          if isinstance(value, dict)
          else func(value)
          for key, value in tree.items()
      }
#+END_SRC

*** Transformation sur $N$ niveaux
L'inconvénient de =transformtree_deep= est qu'elle parcourt l'arbre entièrement, tandis qu'il serait parfois utile de ne parcourir que les $N$ premiers niveaux.

#+BEGIN_SRC ipython
  def transformtree_n(func, tree, n):
      """Transform a tree up to a maximum depth by applying a function to its leaves.

      Once the maximum depth is reached, the function is applied, even if it is not a leaf.

      Parameters
      ----------
      func : function
          The function that will transform each leaf, as well as the final depth.

      tree : recursive dict
          The tree to transform.

      n : int
          The maximum depth

      Returns
      -------
      out : recursive dict
          The transformed tree.
      """
      if n > 0:
          return {
              key: transformtree_n(func, value, n - 1)
              if isinstance(value, dict)
              else func(value)
              for key, value in tree.items()
          }
      else:
          return { key: func(value) for key, value in tree.items() }
#+END_SRC

*** Transformation générique
Une sémantique intéressante pour la transformation d'arbre est de considérer que transformer un arbre jusqu'au niveau $-1$ revient à le transformer sans limite de profondeur.

#+BEGIN_SRC ipython
  def transformtree(func, tree, n=-1):
      if n < 0:
          return transformtree_deep(func, tree)
      else:
          return transformtree_n(func, tree, n)
#+END_SRC

** Tris
*** Dictionnaire
Par défaut, le tri sur les entrées d'un dictionnaire se fait sur les clés. On propose la fonction =sorted_items= pour faire un tri sur les valeurs.
#+BEGIN_SRC ipython
  def sorted_items(dictionary, key=operator.itemgetter(1), reverse=False):
      return sorted(dictionary.items(), key=key, reverse=reverse)
#+END_SRC

*** Tri naturel
Il n'y a pas de support natif dans python pour trier des éléments dans l'ordre naturel. La fonction =natural_sort_key= permet d'atteindre ce résultat, lorsque utilisée comme le paramètre =key= d'une fonction de tri.

#+BEGIN_SRC ipython
  def natural_sort_key(key):
      """Transform a key in order to achieve natural sort.
      from https://blog.codinghorror.com/sorting-for-humans-natural-sort-order/
      """
      def convert(text):
          return int(text) if text.isdigit() else text
      return [convert(c) for c in re.split('([0-9]+)', key)]
#+END_SRC

* Fonctionnalités de support (=semeval_util.py=)
:PROPERTIES:
:header-args: :tangle semeval_util.py
:END:

** Imports
#+BEGIN_SRC ipython
  import pickle
#+END_SRC

** Sauvegarde et chargement d'objets sur le disque
On utilise pickle pour sauvegarder et charger des objets qu'il serait long de reconstruire à chaque execution d'un script.
#+BEGIN_SRC ipython

  def save_object(obj, filename):
      pickle.dump(obj, open(filename, 'wb'))

  def load_object(filename):
      return pickle.load(open(filename, 'rb'))
#+END_SRC

* Traitement du langage naturel (=semeval_taln.py=)
:PROPERTIES:
:header-args: :tangle semeval_taln.py
:END:
** Imports
#+BEGIN_SRC ipython
  import os.path
  import math
  from itertools import chain
  from collections import Counter, defaultdict
  from semeval_xml import get_semeval_id, get_related_threads, xmlextract
  from semeval_util import save_object, load_object
#+END_SRC

La classe =Counter= est une sous-classe de =dict=, permettant de compter les occurences d'une clé. Elle est ici utilisée pour représenter des sacs de mots.

** Analyse des questions par un modèle
Étant donné que les questions sont organisées de manière hiérarchiques, à savoir $N$ questions originales, chacune accompagnée de 10 questions reliées, elles vont être représentées par un arbre.

Chaque question est passée dans un modèle de language, produisant ainsi un document.

La fonction =make_document_tree= permet de construire l'arbre des documents, à partir :
 - des questions originales (=original_questions=),
 - d'un modèle de language (=model=),
 - d'une fonction d'extraction de contenu (=content_extractor=)

#+BEGIN_SRC ipython
  def make_document_tree(original_questions, model, content_extractor):
      result = {}
      for org in original_questions:
          orgid = get_semeval_id(org)
          result[orgid] = {
              get_semeval_id(rel): model(content_extractor(rel))
              for rel in get_related_threads(org)
          }
          result[orgid]['org'] = model(content_extractor(org))
      return result
#+END_SRC

L'analyse d'une phrase par un modèle étant une opération possiblement coûteuse, les documents liés aux questions vont être sauvegardées sur le disque afin de ne pas avoir à refaire tous les calculs à chaque fois.

#+BEGIN_SRC ipython
  def make_or_load_document_tree(xml_source, saved_path, model, content_extractor, verbose=False):
      if os.path.isfile(saved_path):
          if verbose:
              print('Loading document tree from', saved_path)
          result = load_object(saved_path)
          return result
      else:
          if verbose:
              print('Creating document tree. This might take a while...')

          extractor = xmlextract(xml_source)
          result = make_document_tree(
              extractor.get_org_elements(), model, content_extractor)

          if verbose:
              print('Saving document tree to', saved_path)
          save_object(result, saved_path)

          return result
#+END_SRC

** Pondération de termes
TF (/Term Frequency/) et IDF (/Inverse Document Frequency/) sont des mesures permettant de pondérer des termes selon leur importance dans un corpus.

Les documents sont ici manipulés comme des sacs de mots, implémentés ici sous forme de compteurs.

*** /Term Frequency/
La TF d'un terme correspond à sa fréquence d'apparition dans l'ensemble des documents.
$$TF(terme, document) = \frac{occurences(terme, document)}{taille(document)}$$

où la taille d'un document correspond au nombre de termes qu'il contient.

Plutôt que de calculer la TF d'un terme dans un document à chaque fois que nécessaire,  la TF de tous les termes d'un document est stockée dans un dictionnaire.

#+BEGIN_SRC ipython

  def term_frequencies(bag):
      documentlen = sum(bag.values())
      return {
          term: occurrences / documentlen
          for term, occurrences in bag.items()
      }
#+END_SRC

*** /Inverse Document Frequency/
L'IDF d'un terme est proportionnelle à l'inverse du nombre de documents dans lesquels il apparaît.
Elle se base sur la DF (/Document Frequency/), correspondant au nombre de document dans lesquels un terme apparaît.
$$DF(terme, corpus) = \norm{\{doc / doc \in corpus \land terme \in doc\}}$$
$$IDF(terme, corpus) = log \left( \frac{taille(corpus)}
{DF(terme, corpus)} \right)$$


De la même manière que pour la TF, l'IDF de tous les termes du corpus est stockée dans un dictionnaire.

#+BEGIN_SRC ipython

  def document_frequencies(corpus):
      result = Counter()
      for document in corpus:
          result.update({term for term in document})
      return result


  def inverse_document_frequencies(corpus, DF=None):
      if DF == None:
          DF = document_frequencies(corpus)
      return {term: math.log2(len(corpus)/docfreq)
              for term, docfreq in DF.items()}
#+END_SRC

*** /Term Frequency - Inverse Document Frequency/ 
La TF-IDF d'un terme correspond à une combinaison de sa TF et de son IDF :
$$\var{TF-IDF}(terme, document, corpus) = TF(terme, document) * IDF(terme, corpus)$$

La TF-IDF d'un terme est implémentée comme une fonction utilisant des dictionnaires TF et IDF passés en paramètres.

#+BEGIN_SRC ipython

  def tf_idf(term, termfreq, inversedocfreq, out_of_corpus_value):
      """Term Frequency - Inverse Document Frequency of a term using dictionaries.

      If the term is not in the inverse document frequency dictionary, this function will use the argument out_of_corpus_value.

      Parameters
      ----------
      term : str
          The term.

      termfreq : dict
          The term frequencies of the document.

      inversedocfreq : dict
          The inverse document frequencies of the corpus.

      Returns
      -------
      out : float
          The TF-IDF value of the term.
      """
      if term not in termfreq:
          return 0
      if term not in inversedocfreq:
          return out_of_corpus_value

      return termfreq[term] * inversedocfreq[term]
#+END_SRC

**** Sacs de mots
Le score TF-IDF d'un sac de mots correspond à la somme des valeurs TF-IDF de ses éléments :
$$\var{score_{TF-IDF}}(sac, document, corpus) =
\sum_{terme \in sac} \var{TF-IDF}(terme, document, corpus)$$


#+BEGIN_SRC ipython

  def tf_idf_bow(bag, termfreq, inversedocfreq, out_of_corpus_value):
      return sum(tf_idf(term, termfreq, inversedocfreq, out_of_corpus_value) * occurences
                 for term, occurences in bag.items())
#+END_SRC

** Similarité de documents
La classe =scorer= regroupe les informations nécessaires pour comparer deux document à l'aide de TF-IDF. Les différents scorer se construisent en fournissant une fonction de score (argument =scorerfunction=) à =scorer=.

#+BEGIN_SRC ipython

  class scorer(object):
      def __init__(self, wordex, sentex, filters,
                   inversedocfreqs, out_of_corpus_value,
                   scorerfunction):
          """

          Parameters
          ----------
          wordex : 

          sentex : 

          filters : 

          Returns
          -------
          out : 

          """
          self.wordex = wordex
          self.sentex = sentex
          self.filters = filters
          self.inversedocfreqs = inversedocfreqs
          self.out_of_corpus_value = out_of_corpus_value
          self.scorerfunction = scorerfunction

      def get_score(self, *args):
          return self.scorerfunction(self, *args)
#+END_SRC
*** Bruteforce

#+BEGIN_SRC ipython
  def create_unit_dict(wordex, sentex, filters, doc):
      result = defaultdict(list)
      for unit in sentex(doc):
          if all(flt(wordex(unit)) for flt in filters):
              result[wordex(unit)].append(unit)
      return result

  def intersection_score(baga, bagb,
                         inversedocfreqs,
                         out_of_corpus_value,
                         score_multiplier='interlen'):
      score = 0
      intersection = baga & bagb
      termfreq = term_frequencies(baga + bagb)

      if score_multiplier == 'interocc':
          for el, count in intersection.items():
              score += tf_idf(el, termfreq, inversedocfreqs, out_of_corpus_value)\
                       ,* count
      else:
          for el in intersection:
              score += tf_idf(el, termfreq, inversedocfreqs, out_of_corpus_value)\
                       ,* len(intersection)

      return score


  def bruteforce_scorer(
          wordex, sentex, filters,
          doca, docb, inversedocfreqs,
          out_of_corpus_value,
          score_multiplier='interlen'):
      unitsa = create_unit_dict(wordex, sentex, filters, doca)
      unitsb = create_unit_dict(wordex, sentex, filters, docb)

      counta = Counter(word for word, occ in unitsa.items() for _ in occ)
      countb = Counter(word for word, occ in unitsb.items() for _ in occ)

      return intersection_score(counta, countb, inversedocfreqs,
                                out_of_corpus_value, score_multiplier)

  def tf_idf_scorer(self, doca, docb):
      """
      Parameters
      ----------
      doca : 

      docb : 

      inversedocfreqs : 

      out_of_corpus_value : 

      Returns
      -------
      out : 
      """
      def bag_maker(doc):
          return Counter(word
                  for word in map(self.wordex, self.sentex(doc))
                  if all(flt(word) for flt in self.filters))
      baga = bag_maker(doca)
      bagb = bag_maker(docb)
      intersection = baga & bagb
      termfreq = term_frequencies(baga + bagb)

      return sum(
          tf_idf(term,
                 termfreq,
                 self.inversedocfreqs,
                 self.out_of_corpus_value) * len(intersection)
          for term, occurences in intersection.items()
      )
#+END_SRC

*** Pondération des entités nommées
#+BEGIN_SRC ipython

  def entity_weighter(unita, unitb, weight):
      entcount = 0
      for tok in chain(unita, unitb):
          if tok.ent_type != 0:
              entcount += 1
      if entcount > 0:
          return weight
      else:
          return 1-weight

  def entityweight_scorer(
          wordex, filters,
          doca, docb, inversedocfreqs,
          out_of_corpus_value,
          score_multiplier='interlen',
          weight=0.6):
      unitsa = create_unit_dict(wordex, lambda x: x, filters, doca)
      unitsb = create_unit_dict(wordex, lambda x: x, filters, docb)

      counta = Counter(word for word, occ in unitsa.items() for _ in occ)
      countb = Counter(word for word, occ in unitsb.items() for _ in occ)

      score = 0
      intersection = counta & countb
      termfreq = term_frequencies(counta + countb)

      if score_multiplier == 'interocc':
          for el, count in intersection.items():
              score += tf_idf(el, termfreq, inversedocfreqs, out_of_corpus_value)\
                       ,* count * entity_weighter(unitsa[el], unitsb[el], weight)
      else:
          for el in intersection:
              score += tf_idf(el, termfreq, inversedocfreqs, out_of_corpus_value)\
                       ,* len(intersection) * entity_weighter(unitsa[el], unitsb[el], weight)
      return score


#+END_SRC

#+RESULTS:
: # Out[3]:

Où =bag_maker= est une fonction retournant un sac de mots.

*** ajouter avec normalisation, ex div par len phrase can

* TODO trouver la différence, si elle existe entre mesure, indicateur et score :noexport:
* Évaluation des approches (=semeval_executable.py=)
:PROPERTIES:
:header-args: :ipython: :tangle semeval_executable.py :exports code :session semexec :eval no-export
:END:
** Imports

#+BEGIN_SRC ipython :shebang "#!/usr/bin/python"
  from itertools import product, combinations
  import spacy
  from spacy.lang.en.stop_words import STOP_WORDS
  from semeval_struct import *
  from semeval_util import *
  from semeval_xml import get_semeval_content
  from semeval_taln import *
#+END_SRC

** Paramètres d'exécution

#+BEGIN_SRC ipython
  debug_mode = False;
  seek_optimal_ner_ponderation = True
#+END_SRC

** Scores
Les scores sont stockés dans un arbre construit à partir de l'arbre des documents.
=compute_relqs_scores= calcule les scores de similarité d'un noeud de l'arbre des documents, en attribuant à chaque question relié son score obtenu en comparaison avec sa question originale.

#+BEGIN_SRC ipython
  def compute_relqs_scores(orgqnode, scorer):
      return {relid: scorer(orgqnode['org'], orgqnode[relid])
              for relid in orgqnode.keys() - {'org'}}
#+END_SRC

=make_score_tree= transforme le premier niveau d'un arbre de documents en lui appliquant =compute_relqs_scores= associé à la fonction de scoring recue en paramètre.

#+BEGIN_SRC ipython
  def make_score_tree(document_tree, scorer):
      return transformtree(
          lambda x: compute_relqs_scores(x, scorer),
          document_tree,
          0
      )
#+END_SRC

*** Écriture des fichiers de prédiction
Semeval fournit un script permettant de noter les performances d'une approche.
Ce script prend en entrée un fichier de prédiction dont chaque ligne correspond à une question reliée et est formatée de la manière suivante :

#+BEGIN_EXAMPLE
orgq_id  relq_id  0  score  true
#+END_EXAMPLE

Les troisième et cinquième colonnes sont sans intérêt pour cette tâche.

Le fichier de prédiction est destiné à être ensuite comparé à un fichier de référence de Semeval, afin d'évaluer les performances du système.

La fonction =write_scores_to_file= permet de générer ce fichier de prédiction.
Les résultats sont triés sur le tas, pour correspondre à l'ordre du fichier de références.

#+BEGIN_SRC ipython
  def write_scores_to_file(scores, filename, verbose=False):
      """Write a semeval score tree to a prediction file.

      Parameters
      ----------
      scores : dict of dict of float
          The scores to write.

      filename : str
         The name of the output file.
      """
      linebuffer = [(orgid, relid, str(0), str(score), 'true')
                    for orgid, relqs in scores.items()
                    for relid, score in relqs.items()]

      linebuffer.sort(key=lambda x: natural_sort_key(x[1]))

      if verbose:
          print('writing scores to', prediction_file)

      with open(filename, 'w') as out:
          out.write('\n'.join(['\t'.join(el) for el in linebuffer]))

#+END_SRC

** Dimensions orthogonales d'une approche
Plusieurs dimensions orthogonales sont envisagées pour appareiller des questions. Ces dimensions sont combinées les unes avec les autres, en faisant un produit cartésien, formant ainsi une approche.

*** Modèle de langage
Un seul modèle de langage est utilisé.
#+BEGIN_SRC ipython
  models = {
      'spacy_en': spacy.load('en')
  }
#+END_SRC

*** Corpus
Les approches sont testées sur les données 2016 et 2017 de Semeval.
#+BEGIN_SRC ipython

  if debug_mode:
      corpuses = {
          'debug': 'debug.xml',
      }
  else:
      corpuses = {
          '2016': 'SemEval2016-Task3-CQA-QL-test-input.xml',
          '2017': 'SemEval2017-task3-English-test-input.xml',
      }
#+END_SRC

*** Extraction de contenu
Deux manières d'extraire du contenu sont envisagées. Elles se différencient au niveau de l'extraction du contenu des questions reliées. La première extrait uniquement le sujet et le corps d'une question, tandis que la seconde extrait également les commentaires des questions reliées.

#+BEGIN_SRC ipython
  extractors = {
      'questions': lambda x: get_semeval_content(x).lower(),
     # 'questions_with_comments': get_semeval_content_with_relcomments
  }
#+END_SRC

Ces fonctions sont fournies dans le fichier =semeval_xml.py=.

*** Filtrage des mots
Les mots d'un sac de mots peuvent être filtrés ou non selon un prédicat.

#+BEGIN_SRC ipython
  MAPPSENT_STOPWORDS = set(open('stopwords_en.txt', 'r').read().splitlines())

  def isnotstopword(word):
      return word not in STOP_WORDS


  def isnotstopword2(word):
      return word not in MAPPSENT_STOPWORDS


  lenfilters = {
      'gtr1': lambda word: len(word) > 1,
      'gtr2': lambda word: len(word) > 2,
      'gtr3': lambda word: len(word) > 3,
      'gtr4': lambda word: len(word) > 4,
  }

  nolenfilters = {
      'nostopwords': isnotstopword2,
  }

  filters = {}
  filters.update(lenfilters)
  filters.update(nolenfilters)
  filters.update({ 'nofilter': lambda x: True })
#+END_SRC

La fonction =nonemptypartitions= est utilisée pour combiner les filtres.
#+BEGIN_SRC ipython
  def nonemptypartitions(iterable):
      for i in range(1, len(iterable) + 1):
          for perm in combinations(iterable, i):
              yield perm


  def join_predicates(iterable_preds):
      def joinedlocal(element):
          for pred in iterable_preds:
              if not pred(element):
                  return False
          return True
      print('joining', *(pred for pred in iterable_preds))
      return joinedlocal


  filters_partition = list(nonemptypartitions(nolenfilters))

  for len_and_nolen in product(nolenfilters, lenfilters):
      filters_partition.append(len_and_nolen)

  for lenfilter in lenfilters:
      filters_partition.append((lenfilter,))

  filters_partition.append(('nofilter',))
#+END_SRC

*** Construction des sacs de mots
Les sacs de mots sont construits à l'aide de deux fonctions.
La première est une fonction d'extraction de caractéristique, qui étant donné un token, renvoie la caractéristique désirée de celui-ci. La deuxième est une fonction d'extraction de phrase, qui étant donné un document, renvoie un itérable contenant des mots.

Chaque méthode de construction de sacs de mots utilise ces deux fonctions.
#+BEGIN_SRC ipython
  def extracttext(tok):
      return tok.text

  def extractlemma(tok):
      return tok.lemma_

  def extractlabel(ent):
      return ent.label_ if hasattr(ent, 'label_') else None

  def getentities(doc):
      return doc.ents or list()

  wordextractors = {
      'text': extracttext,
      'lemma': extractlemma,
      'label': extractlabel,
  }

  sentenceextractors = {
      'entities': getentities,
      'document': lambda x: x,
  }

  morphologic_indicators = {
      'tokens': ('text', 'document'),
      'lemmas': ('lemma', 'document'),
  }

  ner_indicators = {
      'named_entities_text': ('text', 'entities'),
      'named_entities_label': ('label', 'entities'),
  }

  all_indicators = {}
  all_indicators.update(morphologic_indicators)
  all_indicators.update(ner_indicators)

  def getindicatorfunctions(key):
      return (wordextractors[all_indicators[key][0]], sentenceextractors[all_indicators[key][1]])
#+END_SRC

Les fonctions associées aux éléments de =all_indicators= sont destinés à être passés à la fonction =createbowmaker=, retournant une fonction permettant de construire un sac de mots selon les modalité voulues.

#+BEGIN_SRC ipython
  def createbowmaker(wordextractor, sentenceextractor, filters):
      def bowmaker(document):
          return Counter(
              list(filter(lambda x: all(f(x) for f in filters),
                     map(wordextractor, sentenceextractor(document))))
              )

      return bowmaker

#+END_SRC

*** Création des arbres de documents

#+BEGIN_SRC ipython
  training_file = 'SemEval2016-Task3-CQA-QL-train-part1.xml'

  training_doctree = make_or_load_document_tree(
      training_file,
      'train_2016_part1.pickle',
      models['spacy_en'],
      get_semeval_content,
      verbose=True
  )

  inversedocfreqs = {
      wordex + '_' + sentex: inverse_document_frequencies(
          [[wordextractors[wordex](tok) for tok in sentenceextractors[sentex](doc)]
           for org in training_doctree.values()
           for doc in org.values()]
      )
      for wordex, sentex in all_indicators.values()
  }

  doctrees = {
      '_'.join((model, corpus, extractor)): make_or_load_document_tree(
          corpuses[corpus],
          '_'.join((model, corpus, extractor) )+ '.pickle',
          models[model],
          extractors[extractor],
          verbose=True
      )
      for model, corpus, extractor in product(models, corpuses, extractors)
  }
#+END_SRC

** Méthodes                                                          :export:
=getpredfilename= permet de s'assurer que les noms des fichiers de prédiction sont tous construits de la même manière.

#+BEGIN_SRC ipython
  def getpredfilename(doctree, indicator, filterspartition, methodcategory):
      return 'predictions/' + '_'.join((doctree, indicator, *filterspartition,
                       methodcategory, 'scores.pred'))
#+END_SRC


Un script shell est utilisé pour extraire le score MAP d'un fichier de prédiction :
#+BEGIN_SRC sh :shebang "#!/usr/bin/env bash" :exports code :eval never :tangle extractMAP.sh
  prediction=$1

  if echo $prediction | grep --quiet "2016"
  then
      reference=scorer/SemEval2016-Task3-CQA-QL-test.xml.subtaskB.relevancy
  else
      if echo $prediction | grep --quiet "2017"
      then
          reference=scorer/SemEval2017-Task3-CQA-QL-test.xml.subtaskB.relevancy
      else
          reference=scorer/SemEval2016-debug.relevancy
      fi
  fi

  python2 scorer/ev.py $reference $prediction | grep "^MAP" | sed 's/ \+/;/g' | cut -f 4 -d ';'
#+END_SRC

*** hidden utils                                                   :noexport:

#+BEGIN_SRC ipython :tangle no :exports none :results silent
  import subprocess

  # def orgmodetable(matrix, header=False):
  #     maxlen = [0] * len(matrix[0])
  #     for line in matrix:
  #         for i, cell in enumerate(line):
  #             if len(maxlen) <= i or len(cell) > maxlen[i]:
  #                 maxlen[i] = len(cell)

  #     def orgmodeline(line, fill=' '):
  #         joinsep = fill + '|' + fill
  #         return '|' + fill + joinsep.join(
  #             cell + fill * (mlen - len(cell))
  #             for cell, mlen in zip(line, maxlen)
  #         ) + fill + '|'

  #     result = ''
  #     if header:
  #         result = orgmodeline(matrix[0]) + '\n' + \
  #             orgmodeline(('-') * len(maxlen), fill='-') + '\n'
  #         matrix = matrix[1:]
  #     result += '\n'.join(orgmodeline(line) for line in matrix)
  #     return result


  all_filters_descr = {
      'gtr1': '$\leq 1$',
      'gtr2': '$\leq 2$',
      'gtr3': '$\leq 3$',
      'gtr4': '$\leq 4$',
      'nostopwords': 'Mots outils',
      'nofilter': 'Pas de filtre',
  }

  all_indicators_descr = {
      'named_entities_text': 'Textes des entités nommées',
      'named_entities_label': 'Étiquettes des entités nommées',
      'tokens': 'Tokens',
      'lemmas': 'Lemmes',
  }

  all_doctrees_descr = {
      '_'.join((model, corpus, extractor)): corpus
      for model, corpus, extractor in product(models, corpuses, extractors)
  }

  def get_filters_descr(filters):
      return ', '.join(all_filters_descr[key] for key in filters)

  def get_indicator_descr(indicator):
      return all_indicators_descr[indicator]

  def get_doctree_descr(doctree):
      return all_doctrees_descr[doctree]

  def get_map_score(predfilename):
      score = subprocess.run(
          ['./extractMAP.sh', predfilename], stdout=subprocess.PIPE)
      return score.stdout.decode('utf-8').strip('\n')

#+END_SRC

*** Méthodes bruteforce
Les méthodes bruteforce correspondent à tester toutes les combinaisons d'arbres de documents, de sacs de mots et de filtres.
Les méthodes bruteforce sont crées en faisant le produit cartésien des dimensions envisagées.

Les méthodes précédemment générées sont exécutées et les scores produits sont écrits dans les fichiers correspondants.

#+BEGIN_SRC ipython
  bruteforce_methods = (doctrees, all_indicators, filters_partition)


  out_of_corpus_value = max(inversedocfreqs['text_document'].values())

  for doctree, indicator, filterspartition in product(*bruteforce_methods):
      wordex, sentex = all_indicators[indicator]
      customscorer = scorer(
          wordextractors[wordex],
          sentenceextractors[sentex],
          [filters[filterkey] for filterkey in filterspartition],
          inversedocfreqs[wordex + '_' + sentex],
          out_of_corpus_value,
          tf_idf_scorer
      )

      scores = make_score_tree(
          doctrees[doctree],
          customscorer.get_score
      )

      prediction_file = getpredfilename(doctree, indicator, filterspartition, 'bruteforce')
      write_scores_to_file(scores, prediction_file, verbose=True)
#+END_SRC

#+BEGIN_SRC ipython :exports results :results drawer output replace :tangle no :session semexec
  for doctree in doctrees:
      restable = [[get_indicator_descr(indi),
                   get_filters_descr(fltr),
                   get_map_score(getpredfilename(doctree, indi, fltr, 'bruteforce'))]
                  for indi, fltr in product(*bruteforce_methods[1:])]

      restable.sort(key=lambda x: x[2], reverse=True)
      restable.insert(0, ['Sac de mots', 'Filtres', 'Score MAP'])
      print('\\newpage\n' + '*année ' + all_doctrees_descr[doctree] + '*' + '\n')
      print(orgmodetable(restable, header=True))
      print()
#+END_SRC

#+RESULTS:
:RESULTS:
\newpage
*année 2016*

| Sac de mots                    | Filtres               | Score MAP |
|--------------------------------|-----------------------|-----------|
| Lemmes                         | Mots outils, $\leq 2$ | 0.7679    |
| Textes des entités nommées     | Mots outils           | 0.7493    |
| Textes des entités nommées     | Mots outils, $\leq 1$ | 0.7493    |
| Textes des entités nommées     | Mots outils, $\leq 2$ | 0.7493    |
| Textes des entités nommées     | Mots outils, $\leq 3$ | 0.7493    |
| Textes des entités nommées     | Mots outils, $\leq 4$ | 0.7493    |
| Textes des entités nommées     | $\leq 1$              | 0.7493    |
| Textes des entités nommées     | $\leq 2$              | 0.7493    |
| Textes des entités nommées     | $\leq 3$              | 0.7493    |
| Textes des entités nommées     | $\leq 4$              | 0.7493    |
| Textes des entités nommées     | Pas de filtre         | 0.7493    |
| Lemmes                         | Mots outils, $\leq 1$ | 0.7490    |
| Tokens                         | Mots outils, $\leq 2$ | 0.7488    |
| Tokens                         | Mots outils, $\leq 1$ | 0.7446    |
| Lemmes                         | Mots outils           | 0.7424    |
| Tokens                         | Mots outils, $\leq 3$ | 0.7423    |
| Tokens                         | Mots outils, $\leq 4$ | 0.7422    |
| Étiquettes des entités nommées | Mots outils, $\leq 4$ | 0.7369    |
| Étiquettes des entités nommées | $\leq 4$              | 0.7369    |
| Tokens                         | Mots outils           | 0.7322    |
| Lemmes                         | Mots outils, $\leq 3$ | 0.7317    |
| Lemmes                         | $\leq 2$              | 0.7293    |
| Lemmes                         | $\leq 4$              | 0.7292    |
| Tokens                         | $\leq 4$              | 0.7275    |
| Tokens                         | $\leq 2$              | 0.7274    |
| Lemmes                         | $\leq 1$              | 0.7269    |
| Lemmes                         | $\leq 3$              | 0.7253    |
| Tokens                         | $\leq 3$              | 0.7219    |
| Lemmes                         | Mots outils, $\leq 4$ | 0.7202    |
| Étiquettes des entités nommées | Mots outils           | 0.7153    |
| Étiquettes des entités nommées | Mots outils, $\leq 1$ | 0.7153    |
| Étiquettes des entités nommées | Mots outils, $\leq 2$ | 0.7153    |
| Étiquettes des entités nommées | $\leq 1$              | 0.7153    |
| Étiquettes des entités nommées | $\leq 2$              | 0.7153    |
| Étiquettes des entités nommées | Pas de filtre         | 0.7153    |
| Lemmes                         | Pas de filtre         | 0.7148    |
| Tokens                         | $\leq 1$              | 0.7135    |
| Tokens                         | Pas de filtre         | 0.7098    |
| Étiquettes des entités nommées | Mots outils, $\leq 3$ | 0.7081    |
| Étiquettes des entités nommées | $\leq 3$              | 0.7081    |

\newpage
*année 2017*

| Sac de mots                    | Filtres               | Score MAP |
|--------------------------------|-----------------------|-----------|
| Tokens                         | Mots outils, $\leq 1$ | 0.4705    |
| Lemmes                         | Mots outils, $\leq 1$ | 0.4678    |
| Tokens                         | Mots outils, $\leq 2$ | 0.4653    |
| Tokens                         | Mots outils, $\leq 3$ | 0.4650    |
| Lemmes                         | Mots outils, $\leq 2$ | 0.4624    |
| Tokens                         | $\leq 2$              | 0.4623    |
| Tokens                         | Mots outils           | 0.4598    |
| Lemmes                         | Mots outils           | 0.4581    |
| Lemmes                         | Pas de filtre         | 0.4580    |
| Tokens                         | Mots outils, $\leq 4$ | 0.4521    |
| Lemmes                         | $\leq 1$              | 0.4473    |
| Lemmes                         | Mots outils, $\leq 3$ | 0.4458    |
| Tokens                         | $\leq 1$              | 0.4455    |
| Lemmes                         | $\leq 2$              | 0.4425    |
| Lemmes                         | Mots outils, $\leq 4$ | 0.4419    |
| Tokens                         | Pas de filtre         | 0.4418    |
| Tokens                         | $\leq 3$              | 0.4392    |
| Lemmes                         | $\leq 3$              | 0.4389    |
| Lemmes                         | $\leq 4$              | 0.4249    |
| Tokens                         | $\leq 4$              | 0.4153    |
| Textes des entités nommées     | Mots outils, $\leq 3$ | 0.4139    |
| Textes des entités nommées     | Mots outils, $\leq 4$ | 0.4139    |
| Textes des entités nommées     | $\leq 3$              | 0.4139    |
| Textes des entités nommées     | $\leq 4$              | 0.4139    |
| Étiquettes des entités nommées | Mots outils           | 0.4123    |
| Étiquettes des entités nommées | Mots outils, $\leq 1$ | 0.4123    |
| Étiquettes des entités nommées | Mots outils, $\leq 2$ | 0.4123    |
| Étiquettes des entités nommées | $\leq 1$              | 0.4123    |
| Étiquettes des entités nommées | $\leq 2$              | 0.4123    |
| Étiquettes des entités nommées | Pas de filtre         | 0.4123    |
| Étiquettes des entités nommées | Mots outils, $\leq 3$ | 0.4104    |
| Étiquettes des entités nommées | $\leq 3$              | 0.4104    |
| Textes des entités nommées     | Mots outils           | 0.4083    |
| Textes des entités nommées     | Mots outils, $\leq 1$ | 0.4083    |
| Textes des entités nommées     | Mots outils, $\leq 2$ | 0.4083    |
| Textes des entités nommées     | $\leq 1$              | 0.4083    |
| Textes des entités nommées     | $\leq 2$              | 0.4083    |
| Textes des entités nommées     | Pas de filtre         | 0.4083    |
| Étiquettes des entités nommées | Mots outils, $\leq 4$ | 0.4063    |
| Étiquettes des entités nommées | $\leq 4$              | 0.4063    |

:END:


| Année | Score MAP baseline |
|-------+--------------------|
|  2016 |             0.7475 |
|  2017 |             0.4185 |



*** Méthodes pondérées

Le but des méthodes pondérées est d'utiliser plusieurs indicateurs au sein d'une même méthode.
Un exemple d'approche de pondération est d'utiliser les lemmes pour estimer la similarité de phrases,
et de donner une plus grande importance aux lemmes communs qui sont également des entités nommées.

**** Recherche des pondérations optimales
**** Pondération par entités nommées

#+BEGIN_SRC ipython
  ponderated_methods = (doctrees, morphologic_indicators, filters_partition)

  for doctree, indicator, fltrs in product(*ponderated_methods):
      wordex, sentex = all_indicators[indicator]

      scores = make_score_tree(
          doctrees[doctree],
          lambda a, b: entityweight_scorer(
              wordextractors[wordex],
              [filters[filterkey] for filterkey in fltrs],
              a, b, inversedocfreqs[wordex + '_' + sentex],
              out_of_corpus_value
          )
      )

      prediction_file = getpredfilename(doctree, indicator, fltrs, 'nerponderation')
      write_scores_to_file(scores, prediction_file, verbose=True)
#+END_SRC

#+BEGIN_SRC ipython :tangle no :exports results :results output drawer replace
  for doctree in doctrees:
      restable = [[get_indicator_descr(indi),
                   get_filters_descr(fltr),
                   get_map_score(getpredfilename(doctree, indi, fltr, 'nerponderation'))]
                  for indi, fltr in product(*ponderated_methods[1:])]

      restable.sort(key=lambda x: x[2], reverse=True)
      restable.insert(0, ['Sac de mots', 'Filtres', 'Score MAP'])
      print('\\newpage\n' + '*année ' + all_doctrees_descr[doctree] + '*' + '\n')
      print(orgmodetable(restable, header=True))
      print()
#+END_SRC

#+RESULTS:
:RESULTS:
\newpage
*année 2016*

| Sac de mots | Filtres               | Score MAP |
|-------------|-----------------------|-----------|
| Lemmes      | Mots outils, $\leq 2$ | 0.7663    |
| Tokens      | Mots outils, $\leq 2$ | 0.7497    |
| Lemmes      | Mots outils, $\leq 1$ | 0.7474    |
| Tokens      | Mots outils, $\leq 1$ | 0.7446    |
| Tokens      | Mots outils, $\leq 3$ | 0.7430    |
| Tokens      | Mots outils, $\leq 4$ | 0.7422    |
| Lemmes      | Mots outils           | 0.7405    |
| Tokens      | Mots outils           | 0.7319    |
| Lemmes      | Mots outils, $\leq 3$ | 0.7301    |
| Lemmes      | $\leq 4$              | 0.7292    |
| Lemmes      | $\leq 2$              | 0.7287    |
| Tokens      | $\leq 4$              | 0.7264    |
| Tokens      | $\leq 2$              | 0.7254    |
| Lemmes      | $\leq 1$              | 0.7239    |
| Lemmes      | $\leq 3$              | 0.7237    |
| Tokens      | $\leq 3$              | 0.7214    |
| Lemmes      | Mots outils, $\leq 4$ | 0.7202    |
| Lemmes      | Pas de filtre         | 0.7167    |
| Tokens      | $\leq 1$              | 0.7142    |
| Tokens      | Pas de filtre         | 0.7078    |

\newpage
*année 2017*

| Sac de mots | Filtres               | Score MAP |
|-------------|-----------------------|-----------|
| Tokens      | Mots outils, $\leq 1$ | 0.4725    |
| Lemmes      | Mots outils, $\leq 1$ | 0.4707    |
| Tokens      | Mots outils, $\leq 3$ | 0.4658    |
| Tokens      | Mots outils, $\leq 2$ | 0.4651    |
| Tokens      | Mots outils           | 0.4622    |
| Tokens      | $\leq 2$              | 0.4621    |
| Lemmes      | Mots outils, $\leq 2$ | 0.4618    |
| Lemmes      | Mots outils           | 0.4599    |
| Tokens      | Mots outils, $\leq 4$ | 0.4521    |
| Lemmes      | Pas de filtre         | 0.4509    |
| Lemmes      | $\leq 1$              | 0.4477    |
| Tokens      | $\leq 1$              | 0.4475    |
| Lemmes      | Mots outils, $\leq 3$ | 0.4432    |
| Lemmes      | $\leq 2$              | 0.4424    |
| Lemmes      | Mots outils, $\leq 4$ | 0.4413    |
| Tokens      | $\leq 3$              | 0.4412    |
| Tokens      | Pas de filtre         | 0.4412    |
| Lemmes      | $\leq 3$              | 0.4387    |
| Lemmes      | $\leq 4$              | 0.4252    |
| Tokens      | $\leq 4$              | 0.4124    |

:END:

* Debug                          :noexport:
#+BEGIN_SRC ipython :results output replace drawer :eval noexport :session semexec :tangle no

  if debug_mode:
      for filterspartition in filters_partition:
          wordex, sentex = 'label', 'entities'
          bowmakerfunc = createbowmaker(
              wordextractors[wordex], sentenceextractors[sentex],
              [filters[filterkey] for filterkey in filterspartition])


          custom_scores = make_score_tree(
              doctrees['spacy_en_debug_questions'],
              lambda a, b: bruteforce_scorer(
                  wordextractors[wordex],
                  sentenceextractors[sentex],
                  [filters[filterkey] for filterkey in filterspartition],
                  a, b, inversedocfreqs[wordex + '_' + sentex],
                  out_of_corpus_value
              )
          )
          print({k: custom_scores[k] for k in custom_scores.keys() & printsubset})

          customscorer = scorer(
              wordextractors[wordex],
              sentenceextractors[sentex],
              [filters[filterkey] for filterkey in filterspartition],
              inversedocfreqs[wordex + '_' + sentex],
              out_of_corpus_value,
              tf_idf_scorer
          )

          scores = make_score_tree(
              doctrees[doctree],
              lambda a, b: customscorer.get_score(
                  a, b))

          printsubset = {'Q318'}
          print({k: scores[k] for k in scores.keys() & printsubset})
          print()
          # prediction_file = getpredfilename('spacy_en_2016_questions', 'named_entities_label', filterspartition)
          # print('writing scores to', prediction_file)
          # write_scores_to_file(scores, prediction_file)
#+END_SRC

#+RESULTS:
:RESULTS:
:END:


* perspectives

 - Ajouter des dimensions (catégorie grammaticale, etc) et ne conserver que les $n$ meilleurs et les $n$ pires, en partant du principe qu'il est plus intéressant d'analyser les combinaisons de paramètres ne fonctionnant pas et celles fonctionnant.


dictionnaire synonymes
+ de filtres
combinaison entités et (lemmes ou texte)
catégories grammaticales

le score 
le nombre de 
